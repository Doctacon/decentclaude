{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BigQuery Exploration with bq-* Utilities\n",
    "\n",
    "This notebook demonstrates how to use the BigQuery utilities for data exploration.\n",
    "\n",
    "We'll explore public datasets using:\n",
    "- `bq-profile` - Generate comprehensive data profiles\n",
    "- `bq-lineage` - Explore table dependencies\n",
    "- `bq-schema-diff` - Compare table schemas\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from google.cloud import bigquery\n",
    "from pathlib import Path\n",
    "\n",
    "# Set plot style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Initialize BigQuery client\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Path to utilities\n",
    "UTILS_DIR = Path('../bin/data-utils')\n",
    "\n",
    "print('Setup complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_util(util_name, args, parse_json=True):\n",
    "    \"\"\"Run a bq-* utility and return output.\"\"\"\n",
    "    util_path = UTILS_DIR / util_name\n",
    "    cmd = [str(util_path)] + args\n",
    "    \n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    \n",
    "    if result.returncode != 0:\n",
    "        print(f'Error: {result.stderr}')\n",
    "        return None\n",
    "    \n",
    "    if parse_json:\n",
    "        try:\n",
    "            return json.loads(result.stdout)\n",
    "        except json.JSONDecodeError:\n",
    "            print('Warning: Could not parse JSON output')\n",
    "            return result.stdout\n",
    "    return result.stdout\n",
    "\n",
    "def display_profile_summary(profile):\n",
    "    \"\"\"Display key metrics from a table profile.\"\"\"\n",
    "    meta = profile['table_overview']\n",
    "    \n",
    "    print(f\"Table: {profile['table_id']}\")\n",
    "    print(f\"Rows: {meta['num_rows']:,}\")\n",
    "    print(f\"Size: {meta['num_bytes']:,} bytes\")\n",
    "    print(f\"Columns: {meta['num_columns']}\")\n",
    "    print(f\"Created: {meta['created']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Profile Public Dataset: Stack Overflow\n",
    "\n",
    "Let's profile the Stack Overflow posts table from BigQuery's public datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profile the Stack Overflow posts table\n",
    "table_id = 'bigquery-public-data.stackoverflow.posts_questions'\n",
    "\n",
    "print('Profiling Stack Overflow posts table...')\n",
    "profile = run_util('bq-profile', [table_id, '--format=json', '--sample-size=5'])\n",
    "\n",
    "if profile:\n",
    "    display_profile_summary(profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Data Type Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if profile:\n",
    "    # Create DataFrame from data type distribution\n",
    "    type_dist = profile['data_type_distribution']\n",
    "    df_types = pd.DataFrame([\n",
    "        {'Type': k, 'Count': v} for k, v in type_dist.items()\n",
    "    ])\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=df_types, x='Type', y='Count', palette='viridis')\n",
    "    plt.title('Data Type Distribution')\n",
    "    plt.xlabel('Data Type')\n",
    "    plt.ylabel('Number of Columns')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Column Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if profile:\n",
    "    col_stats = profile['column_statistics']\n",
    "    \n",
    "    # Create DataFrame of null percentages\n",
    "    null_data = []\n",
    "    for col_name, stats in col_stats.items():\n",
    "        null_data.append({\n",
    "            'Column': col_name,\n",
    "            'Null %': stats.get('null_percentage', 0),\n",
    "            'Uniqueness': stats.get('uniqueness_ratio', 0)\n",
    "        })\n",
    "    \n",
    "    df_nulls = pd.DataFrame(null_data).sort_values('Null %', ascending=False)\n",
    "    \n",
    "    # Plot null percentages\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(data=df_nulls, x='Column', y='Null %', palette='coolwarm')\n",
    "    plt.title('Null Percentage by Column')\n",
    "    plt.xlabel('Column')\n",
    "    plt.ylabel('Null %')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print('\\nColumns with highest null percentages:')\n",
    "    print(df_nulls.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Uniqueness Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if profile:\n",
    "    # Plot uniqueness ratios\n",
    "    df_unique = df_nulls.sort_values('Uniqueness', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(data=df_unique, x='Column', y='Uniqueness', palette='magma')\n",
    "    plt.title('Column Uniqueness Ratio (1.0 = all unique values)')\n",
    "    plt.xlabel('Column')\n",
    "    plt.ylabel('Uniqueness Ratio')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.axhline(y=1.0, color='r', linestyle='--', label='Perfect Uniqueness')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print('\\nPotential primary key candidates (uniqueness >= 0.99):')\n",
    "    pk_candidates = df_unique[df_unique['Uniqueness'] >= 0.99]\n",
    "    print(pk_candidates[['Column', 'Uniqueness']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Schema Comparison: Compare Two Versions\n",
    "\n",
    "Let's compare schemas of different tables to understand schema evolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare two public dataset tables\n",
    "table_a = 'bigquery-public-data.stackoverflow.posts_questions'\n",
    "table_b = 'bigquery-public-data.stackoverflow.posts_answers'\n",
    "\n",
    "print(f'Comparing schemas:\\n  A: {table_a}\\n  B: {table_b}\\n')\n",
    "\n",
    "schema_diff = run_util('bq-schema-diff', [table_a, table_b, '--format=json'])\n",
    "\n",
    "if schema_diff:\n",
    "    print(f\"Identical: {schema_diff['identical']}\")\n",
    "    print(f\"\\nSummary:\")\n",
    "    print(f\"  Fields only in A: {schema_diff['summary']['fields_only_in_a']}\")\n",
    "    print(f\"  Fields only in B: {schema_diff['summary']['fields_only_in_b']}\")\n",
    "    print(f\"  Type changes: {schema_diff['summary']['type_changes']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if schema_diff and not schema_diff['identical']:\n",
    "    # Display fields only in A\n",
    "    if schema_diff['only_in_a']:\n",
    "        print('\\nFields only in Table A:')\n",
    "        df_a = pd.DataFrame(schema_diff['only_in_a'])\n",
    "        display(df_a)\n",
    "    \n",
    "    # Display fields only in B\n",
    "    if schema_diff['only_in_b']:\n",
    "        print('\\nFields only in Table B:')\n",
    "        df_b = pd.DataFrame(schema_diff['only_in_b'])\n",
    "        display(df_b)\n",
    "    \n",
    "    # Display type changes\n",
    "    if schema_diff['type_changes']:\n",
    "        print('\\nType Changes:')\n",
    "        df_changes = pd.DataFrame(schema_diff['type_changes'])\n",
    "        display(df_changes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Lineage Analysis\n",
    "\n",
    "Explore table dependencies to understand data lineage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Lineage analysis works best with views and materialized views\n",
    "# For this demo, we'll use a hypothetical example structure\n",
    "\n",
    "# Example: Analyze lineage of a table\n",
    "# Uncomment and replace with your own table that has dependencies\n",
    "# lineage_table = 'your-project.your-dataset.your-view'\n",
    "# lineage = run_util('bq-lineage', [lineage_table, '--format=json'])\n",
    "\n",
    "# if lineage:\n",
    "#     print(f\"Table: {lineage['table_id']}\")\n",
    "#     print(f\"Direction: {lineage['direction']}\")\n",
    "#     print(f\"\\nUpstream dependencies: {len(lineage['upstream'])}\")\n",
    "#     for table in lineage['upstream']:\n",
    "#         print(f\"  <- {table}\")\n",
    "#     \n",
    "#     print(f\"\\nDownstream dependencies: {len(lineage['downstream'])}\")\n",
    "#     for table in lineage['downstream']:\n",
    "#         print(f\"  -> {table}\")\n",
    "\n",
    "print('Lineage analysis example (replace with your own view/table):')\n",
    "print('Uncomment the code above and provide a table with dependencies')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Multi-Table Profiling\n",
    "\n",
    "Profile multiple tables and compare key metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profile multiple related tables\n",
    "tables_to_profile = [\n",
    "    'bigquery-public-data.stackoverflow.posts_questions',\n",
    "    'bigquery-public-data.stackoverflow.posts_answers',\n",
    "]\n",
    "\n",
    "profiles = {}\n",
    "for table in tables_to_profile:\n",
    "    print(f'Profiling {table}...')\n",
    "    profile = run_util('bq-profile', [table, '--format=json'])\n",
    "    if profile:\n",
    "        profiles[table] = profile\n",
    "        display_profile_summary(profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Table Sizes and Row Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if profiles:\n",
    "    # Extract metrics for comparison\n",
    "    comparison_data = []\n",
    "    for table_id, profile in profiles.items():\n",
    "        meta = profile['table_overview']\n",
    "        # Shorten table names for display\n",
    "        short_name = table_id.split('.')[-1]\n",
    "        comparison_data.append({\n",
    "            'Table': short_name,\n",
    "            'Rows': meta['num_rows'],\n",
    "            'Size (GB)': meta['num_bytes'] / (1024**3),\n",
    "            'Columns': meta['num_columns']\n",
    "        })\n",
    "    \n",
    "    df_comparison = pd.DataFrame(comparison_data)\n",
    "    \n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Row counts\n",
    "    sns.barplot(data=df_comparison, x='Table', y='Rows', ax=axes[0], palette='Set2')\n",
    "    axes[0].set_title('Row Count Comparison')\n",
    "    axes[0].set_ylabel('Rows')\n",
    "    axes[0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Table sizes\n",
    "    sns.barplot(data=df_comparison, x='Table', y='Size (GB)', ax=axes[1], palette='Set2')\n",
    "    axes[1].set_title('Table Size Comparison')\n",
    "    axes[1].set_ylabel('Size (GB)')\n",
    "    axes[1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Column counts\n",
    "    sns.barplot(data=df_comparison, x='Table', y='Columns', ax=axes[2], palette='Set2')\n",
    "    axes[2].set_title('Column Count Comparison')\n",
    "    axes[2].set_ylabel('Columns')\n",
    "    axes[2].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print('\\nTable Comparison:')\n",
    "    display(df_comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Query and Visualize Actual Data\n",
    "\n",
    "Combine utility insights with actual data queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query sample data from Stack Overflow\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    EXTRACT(YEAR FROM creation_date) as year,\n",
    "    COUNT(*) as question_count\n",
    "FROM `bigquery-public-data.stackoverflow.posts_questions`\n",
    "WHERE creation_date >= '2015-01-01'\n",
    "GROUP BY year\n",
    "ORDER BY year\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "df_questions = client.query(query).to_dataframe()\n",
    "\n",
    "# Plot questions over time\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df_questions['year'], df_questions['question_count'], marker='o', linewidth=2)\n",
    "plt.title('Stack Overflow Questions by Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Questions')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "display(df_questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Table Profiling** - Using `bq-profile` to analyze table structure and statistics\n",
    "2. **Schema Comparison** - Using `bq-schema-diff` to identify schema differences\n",
    "3. **Lineage Analysis** - Using `bq-lineage` to explore table dependencies\n",
    "4. **Multi-Table Analysis** - Comparing metrics across multiple tables\n",
    "5. **Data Visualization** - Combining utility outputs with data queries\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Apply these techniques to your own BigQuery datasets\n",
    "- Automate data quality checks using these utilities\n",
    "- Create dashboards from the profiling data\n",
    "- Build data catalogs using schema and lineage information"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
