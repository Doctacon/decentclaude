#!/usr/bin/env python3
"""
bq-table-compare - Detailed comparison of two BigQuery tables

Usage:
  bq-table-compare <table_a> <table_b> [options]
  bq-table-compare --pairs-file=<file> [options]
  echo "table1:table2" | bq-table-compare --parallel 2

Arguments:
  table_a    First table ID (format: project.dataset.table)
  table_b    Second table ID (format: project.dataset.table)

Options:
  --format=<format>     Output format: text, json (default: text)
  --sample-size=<n>     Number of rows to sample for comparison (default: 100)
  --skip-stats          Skip statistical comparisons (faster)
  --skip-samples        Skip sample data comparison
  --parallel=<n>        Number of parallel workers for batch comparison (default: 4)
  --progress            Show progress bar during batch comparison
  --pairs-file=<file>   Read table pairs from file (one pair per line, format: table_a:table_b)
  --help, -h            Show this help message

Examples:
  bq-table-compare project.staging.users project.prod.users
  bq-table-compare myproject.dataset.table_v1 myproject.dataset.table_v2 --format=json
  bq-table-compare project.staging.data project.prod.data --sample-size=1000
  bq-table-compare --parallel 2 --pairs-file=table_pairs.txt --progress
"""

import sys
import json
import argparse
from typing import Dict, List, Set, Tuple, Any, Optional
from google.cloud import bigquery
from datetime import datetime
from multiprocessing import Pool, cpu_count
from functools import partial

try:
    from rich.progress import Progress, SpinnerColumn, BarColumn, TextColumn, TimeRemainingColumn
    from rich.console import Console
    RICH_AVAILABLE = True
except ImportError:
    RICH_AVAILABLE = False


class Colors:
    """ANSI color codes for terminal output"""
    RED = '\033[0;31m'
    GREEN = '\033[0;32m'
    YELLOW = '\033[1;33m'
    BLUE = '\033[0;34m'
    CYAN = '\033[0;36m'
    MAGENTA = '\033[0;35m'
    RESET = '\033[0m'
    BOLD = '\033[1m'


class TableComparison:
    """Main class for comparing two BigQuery tables"""

    def __init__(self, client: bigquery.Client, table_a_id: str, table_b_id: str,
                 sample_size: int = 100, skip_stats: bool = False, skip_samples: bool = False):
        self.client = client
        self.table_a_id = table_a_id
        self.table_b_id = table_b_id
        self.sample_size = sample_size
        self.skip_stats = skip_stats
        self.skip_samples = skip_samples

        self.table_a = None
        self.table_b = None
        self.results = {}

    def run_comparison(self) -> dict:
        """Run all comparison checks and return results"""
        try:
            # Load table metadata
            self.table_a = self.client.get_table(self.table_a_id)
            self.table_b = self.client.get_table(self.table_b_id)

            # Run comparisons
            self.results['metadata'] = self._compare_metadata()
            self.results['row_counts'] = self._compare_row_counts()
            self.results['schema'] = self._compare_schemas()

            if not self.skip_stats:
                self.results['statistics'] = self._compare_statistics()

            if not self.skip_samples:
                self.results['samples'] = self._compare_samples()

            self.results['summary'] = self._generate_summary()

            return self.results

        except Exception as e:
            print(f"{Colors.RED}Error during comparison: {str(e)}{Colors.RESET}", file=sys.stderr)
            sys.exit(1)

    def _compare_metadata(self) -> dict:
        """Compare table metadata"""
        return {
            'table_a': {
                'created': self.table_a.created.isoformat() if self.table_a.created else None,
                'modified': self.table_a.modified.isoformat() if self.table_a.modified else None,
                'table_type': self.table_a.table_type,
                'partitioning': str(self.table_a.time_partitioning) if self.table_a.time_partitioning else None,
                'clustering': self.table_a.clustering_fields or []
            },
            'table_b': {
                'created': self.table_b.created.isoformat() if self.table_b.created else None,
                'modified': self.table_b.modified.isoformat() if self.table_b.modified else None,
                'table_type': self.table_b.table_type,
                'partitioning': str(self.table_b.time_partitioning) if self.table_b.time_partitioning else None,
                'clustering': self.table_b.clustering_fields or []
            }
        }

    def _compare_row_counts(self) -> dict:
        """Compare row counts between tables"""
        count_a = self.table_a.num_rows
        count_b = self.table_b.num_rows

        difference = count_b - count_a
        percent_diff = (difference / count_a * 100) if count_a > 0 else float('inf')

        return {
            'table_a_rows': count_a,
            'table_b_rows': count_b,
            'difference': difference,
            'percent_difference': percent_diff,
            'identical': count_a == count_b
        }

    def _get_table_schema_dict(self, table) -> Dict[str, dict]:
        """Get schema as a dictionary with detailed field information"""
        schema_dict = {}
        for field in table.schema:
            field_info = {
                'type': field.field_type,
                'mode': field.mode,
                'description': field.description or ''
            }

            if field.field_type == 'RECORD':
                nested = []
                for nested_field in field.fields:
                    nested.append({
                        'name': nested_field.name,
                        'type': nested_field.field_type,
                        'mode': nested_field.mode
                    })
                field_info['nested_fields'] = nested

            schema_dict[field.name] = field_info

        return schema_dict

    def _compare_schemas(self) -> dict:
        """Compare schemas of both tables"""
        schema_a = self._get_table_schema_dict(self.table_a)
        schema_b = self._get_table_schema_dict(self.table_b)

        keys_a = set(schema_a.keys())
        keys_b = set(schema_b.keys())

        only_in_a = list(keys_a - keys_b)
        only_in_b = list(keys_b - keys_a)

        type_changes = []
        for key in keys_a & keys_b:
            if schema_a[key] != schema_b[key]:
                type_changes.append({
                    'field': key,
                    'table_a': schema_a[key],
                    'table_b': schema_b[key]
                })

        return {
            'identical': len(only_in_a) == 0 and len(only_in_b) == 0 and len(type_changes) == 0,
            'only_in_a': only_in_a,
            'only_in_b': only_in_b,
            'type_changes': type_changes,
            'schema_a': schema_a,
            'schema_b': schema_b
        }

    def _get_numeric_columns(self, schema_dict: dict) -> List[str]:
        """Extract numeric column names from schema"""
        numeric_types = {'INTEGER', 'INT64', 'FLOAT', 'FLOAT64', 'NUMERIC', 'BIGNUMERIC'}
        return [
            name for name, info in schema_dict.items()
            if info['type'] in numeric_types
        ]

    def _compare_statistics(self) -> dict:
        """Compare statistical distributions for numeric columns"""
        schema_a = self._get_table_schema_dict(self.table_a)
        schema_b = self._get_table_schema_dict(self.table_b)

        # Find common numeric columns
        numeric_a = set(self._get_numeric_columns(schema_a))
        numeric_b = set(self._get_numeric_columns(schema_b))
        common_numeric = list(numeric_a & numeric_b)

        if not common_numeric:
            return {'message': 'No common numeric columns for statistical comparison'}

        stats_comparison = {}

        for column in common_numeric[:10]:  # Limit to first 10 columns to avoid long queries
            try:
                stats_a = self._get_column_stats(self.table_a_id, column)
                stats_b = self._get_column_stats(self.table_b_id, column)

                stats_comparison[column] = {
                    'table_a': stats_a,
                    'table_b': stats_b,
                    'mean_diff': stats_b['mean'] - stats_a['mean'] if stats_a['mean'] and stats_b['mean'] else None,
                    'min_diff': stats_b['min'] - stats_a['min'] if stats_a['min'] and stats_b['min'] else None,
                    'max_diff': stats_b['max'] - stats_a['max'] if stats_a['max'] and stats_b['max'] else None
                }
            except Exception as e:
                stats_comparison[column] = {'error': str(e)}

        return {
            'columns_analyzed': common_numeric[:10],
            'total_numeric_columns': len(common_numeric),
            'statistics': stats_comparison
        }

    def _get_column_stats(self, table_id: str, column: str) -> dict:
        """Get basic statistics for a numeric column"""
        query = f"""
        SELECT
            MIN(`{column}`) as min_val,
            MAX(`{column}`) as max_val,
            AVG(`{column}`) as mean_val,
            STDDEV(`{column}`) as stddev_val,
            COUNT(DISTINCT `{column}`) as distinct_count,
            COUNT(`{column}`) as non_null_count,
            APPROX_QUANTILES(`{column}`, 100)[OFFSET(50)] as median_val
        FROM `{table_id}`
        WHERE `{column}` IS NOT NULL
        """

        result = list(self.client.query(query).result())[0]

        return {
            'min': float(result['min_val']) if result['min_val'] is not None else None,
            'max': float(result['max_val']) if result['max_val'] is not None else None,
            'mean': float(result['mean_val']) if result['mean_val'] is not None else None,
            'stddev': float(result['stddev_val']) if result['stddev_val'] is not None else None,
            'median': float(result['median_val']) if result['median_val'] is not None else None,
            'distinct_count': int(result['distinct_count']),
            'non_null_count': int(result['non_null_count'])
        }

    def _compare_samples(self) -> dict:
        """Compare sample data from both tables"""
        try:
            # Get common columns
            schema_a = self._get_table_schema_dict(self.table_a)
            schema_b = self._get_table_schema_dict(self.table_b)
            common_cols = list(set(schema_a.keys()) & set(schema_b.keys()))

            if not common_cols:
                return {'message': 'No common columns for sample comparison'}

            # Limit columns to avoid huge queries
            sample_cols = common_cols[:20]
            cols_str = ', '.join([f'`{col}`' for col in sample_cols])

            # Sample from both tables
            query_a = f"SELECT {cols_str} FROM `{self.table_a_id}` LIMIT {self.sample_size}"
            query_b = f"SELECT {cols_str} FROM `{self.table_b_id}` LIMIT {self.sample_size}"

            samples_a = [dict(row) for row in self.client.query(query_a).result()]
            samples_b = [dict(row) for row in self.client.query(query_b).result()]

            return {
                'columns_sampled': sample_cols,
                'sample_size': self.sample_size,
                'samples_retrieved_a': len(samples_a),
                'samples_retrieved_b': len(samples_b),
                'sample_data_a': samples_a[:5],  # Only include first 5 for display
                'sample_data_b': samples_b[:5]
            }
        except Exception as e:
            return {'error': str(e)}

    def _generate_summary(self) -> dict:
        """Generate overall comparison summary"""
        issues = []

        # Row count issues
        if not self.results['row_counts']['identical']:
            diff = self.results['row_counts']['difference']
            pct = self.results['row_counts']['percent_difference']
            issues.append(f"Row count differs by {diff:,} rows ({pct:.2f}%)")

        # Schema issues
        schema = self.results['schema']
        if not schema['identical']:
            if schema['only_in_a']:
                issues.append(f"{len(schema['only_in_a'])} fields only in Table A")
            if schema['only_in_b']:
                issues.append(f"{len(schema['only_in_b'])} fields only in Table B")
            if schema['type_changes']:
                issues.append(f"{len(schema['type_changes'])} fields with type changes")

        return {
            'identical': len(issues) == 0,
            'issues_found': len(issues),
            'issues': issues,
            'tables_comparable': True
        }


def print_text_report(table_a_id: str, table_b_id: str, results: dict):
    """Print a formatted text report of table comparison"""

    print(f"\n{Colors.CYAN}{Colors.BOLD}BigQuery Table Comparison{Colors.RESET}")
    print(f"{Colors.BLUE}Table A:{Colors.RESET} {table_a_id}")
    print(f"{Colors.BLUE}Table B:{Colors.RESET} {table_b_id}")
    print("=" * 80)

    # Row Counts
    row_counts = results['row_counts']
    print(f"\n{Colors.BOLD}Row Counts{Colors.RESET}")
    print(f"  Table A: {row_counts['table_a_rows']:,}")
    print(f"  Table B: {row_counts['table_b_rows']:,}")
    print(f"  Difference: {row_counts['difference']:,} ({row_counts['percent_difference']:.2f}%)")

    if row_counts['identical']:
        print(f"  {Colors.GREEN}✓ Row counts match{Colors.RESET}")
    else:
        print(f"  {Colors.YELLOW}⚠ Row counts differ{Colors.RESET}")

    # Schema Comparison
    schema = results['schema']
    print(f"\n{Colors.BOLD}Schema Comparison{Colors.RESET}")

    if schema['only_in_a']:
        print(f"  {Colors.RED}Fields only in Table A ({len(schema['only_in_a'])}):{Colors.RESET}")
        for field in schema['only_in_a'][:5]:
            print(f"    − {field}")
        if len(schema['only_in_a']) > 5:
            print(f"    ... and {len(schema['only_in_a']) - 5} more")

    if schema['only_in_b']:
        print(f"  {Colors.GREEN}Fields only in Table B ({len(schema['only_in_b'])}):{Colors.RESET}")
        for field in schema['only_in_b'][:5]:
            print(f"    + {field}")
        if len(schema['only_in_b']) > 5:
            print(f"    ... and {len(schema['only_in_b']) - 5} more")

    if schema['type_changes']:
        print(f"  {Colors.YELLOW}Fields with type changes ({len(schema['type_changes'])}):{Colors.RESET}")
        for change in schema['type_changes'][:5]:
            print(f"    ~ {change['field']}: {change['table_a']['type']} → {change['table_b']['type']}")
        if len(schema['type_changes']) > 5:
            print(f"    ... and {len(schema['type_changes']) - 5} more")

    if schema['identical']:
        print(f"  {Colors.GREEN}✓ Schemas are identical{Colors.RESET}")

    # Statistical Comparison
    if 'statistics' in results and 'statistics' in results['statistics']:
        print(f"\n{Colors.BOLD}Statistical Comparison{Colors.RESET}")
        stats = results['statistics']['statistics']
        cols_analyzed = results['statistics']['columns_analyzed']

        print(f"  Columns analyzed: {len(cols_analyzed)}")

        for col in list(stats.keys())[:3]:  # Show first 3
            if 'error' not in stats[col]:
                stat = stats[col]
                print(f"\n  {Colors.CYAN}{col}:{Colors.RESET}")
                print(f"    Table A - Mean: {stat['table_a']['mean']:.2f}, Min: {stat['table_a']['min']:.2f}, Max: {stat['table_a']['max']:.2f}")
                print(f"    Table B - Mean: {stat['table_b']['mean']:.2f}, Min: {stat['table_b']['min']:.2f}, Max: {stat['table_b']['max']:.2f}")
                if stat['mean_diff'] is not None:
                    print(f"    Δ Mean: {stat['mean_diff']:+.2f}")

    # Sample Comparison
    if 'samples' in results and 'sample_data_a' in results['samples']:
        print(f"\n{Colors.BOLD}Sample Data{Colors.RESET}")
        samples = results['samples']
        print(f"  Columns sampled: {len(samples['columns_sampled'])}")
        print(f"  Rows retrieved: Table A = {samples['samples_retrieved_a']}, Table B = {samples['samples_retrieved_b']}")

    # Summary
    summary = results['summary']
    print(f"\n{Colors.CYAN}{Colors.BOLD}Summary{Colors.RESET}")

    if summary['identical']:
        print(f"  {Colors.GREEN}✓ Tables are identical{Colors.RESET}")
    else:
        print(f"  {Colors.YELLOW}⚠ Found {summary['issues_found']} difference(s):{Colors.RESET}")
        for issue in summary['issues']:
            print(f"    • {issue}")

    print("=" * 80 + "\n")


def print_json_report(table_a_id: str, table_b_id: str, results: dict):
    """Print a JSON report of table comparison"""
    output = {
        'table_a': table_a_id,
        'table_b': table_b_id,
        'timestamp': datetime.now().isoformat(),
        'comparison': results
    }
    print(json.dumps(output, indent=2, default=str))


def compare_single_pair_wrapper(table_pair: Tuple[str, str], sample_size: int,
                                skip_stats: bool, skip_samples: bool) -> Dict:
    """
    Compare a single pair of tables (wrapper for parallel execution).

    Args:
        table_pair: Tuple of (table_a, table_b)
        sample_size: Number of rows to sample
        skip_stats: Skip statistical comparisons
        skip_samples: Skip sample data comparison

    Returns:
        Comparison result dictionary
    """
    table_a, table_b = table_pair

    try:
        # Create new client for this process
        client = bigquery.Client()

        # Run comparison
        comparer = TableComparison(
            client,
            table_a,
            table_b,
            sample_size=sample_size,
            skip_stats=skip_stats,
            skip_samples=skip_samples
        )
        results = comparer.run_comparison()

        return {
            'table_a': table_a,
            'table_b': table_b,
            'success': True,
            'results': results,
            'identical': results['summary']['identical']
        }
    except Exception as e:
        return {
            'table_a': table_a,
            'table_b': table_b,
            'success': False,
            'error': str(e)
        }


def compare_batch_pairs(table_pairs: List[Tuple[str, str]], sample_size: int,
                       skip_stats: bool, skip_samples: bool, num_workers: int,
                       show_progress: bool) -> List[Dict]:
    """
    Compare multiple table pairs in parallel.

    Args:
        table_pairs: List of (table_a, table_b) tuples
        sample_size: Number of rows to sample
        skip_stats: Skip statistical comparisons
        skip_samples: Skip sample data comparison
        num_workers: Number of parallel workers
        show_progress: Whether to show progress bar

    Returns:
        List of comparison results
    """
    # Create partial function with fixed arguments
    compare_func = partial(
        compare_single_pair_wrapper,
        sample_size=sample_size,
        skip_stats=skip_stats,
        skip_samples=skip_samples
    )

    results = []

    if show_progress and RICH_AVAILABLE:
        console = Console()
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
            TimeRemainingColumn(),
            console=console
        ) as progress:
            task = progress.add_task(f"Comparing {len(table_pairs)} pairs", total=len(table_pairs))

            with Pool(num_workers) as pool:
                for result in pool.imap_unordered(compare_func, table_pairs):
                    results.append(result)
                    if result['success']:
                        status = "✓" if result['identical'] else "≠"
                    else:
                        status = "✗"
                    progress.console.print(f"{status} {result['table_a']} vs {result['table_b']}")
                    progress.advance(task)
    else:
        # No progress bar
        with Pool(num_workers) as pool:
            results = list(pool.map(compare_func, table_pairs))

    return results


def print_batch_summary(results: List[Dict], output_format: str):
    """
    Print summary of batch comparison results.

    Args:
        results: List of comparison results
        output_format: Output format (text, json)
    """
    successful = [r for r in results if r['success']]
    failed = [r for r in results if not r['success']]
    identical = [r for r in successful if r['identical']]
    different = [r for r in successful if not r['identical']]

    if output_format == "json":
        # JSON output with all comparisons
        output = {
            'batch_summary': {
                'total_pairs': len(results),
                'successful': len(successful),
                'failed': len(failed),
                'identical': len(identical),
                'different': len(different),
                'timestamp': datetime.now().isoformat()
            },
            'comparisons': [
                {
                    'table_a': r['table_a'],
                    'table_b': r['table_b'],
                    'identical': r.get('identical', False),
                    'results': r.get('results', {})
                } for r in successful
            ],
            'errors': [
                {
                    'table_a': r['table_a'],
                    'table_b': r['table_b'],
                    'error': r.get('error')
                } for r in failed
            ]
        }
        print(json.dumps(output, indent=2, default=str))
    else:
        # Text summary
        print(f"\n{Colors.CYAN}{Colors.BOLD}{'=' * 80}{Colors.RESET}")
        print(f"{Colors.CYAN}{Colors.BOLD}Batch Table Comparison Summary{Colors.RESET}")
        print(f"{Colors.CYAN}{Colors.BOLD}{'=' * 80}{Colors.RESET}\n")

        print(f"{Colors.BOLD}Results:{Colors.RESET}")
        print(f"  Total pairs: {len(results)}")
        print(f"  {Colors.GREEN}Successful: {len(successful)}{Colors.RESET}")
        print(f"  {Colors.GREEN}Identical: {len(identical)}{Colors.RESET}")
        print(f"  {Colors.YELLOW}Different: {len(different)}{Colors.RESET}")
        if failed:
            print(f"  {Colors.RED}Failed: {len(failed)}{Colors.RESET}")

        if failed:
            print(f"\n{Colors.RED}{Colors.BOLD}Failed comparisons:{Colors.RESET}")
            for result in failed:
                print(f"  {Colors.RED}✗{Colors.RESET} {result['table_a']} vs {result['table_b']}: {result['error']}")

        if different:
            print(f"\n{Colors.YELLOW}{Colors.BOLD}Different tables:{Colors.RESET}")
            for result in different:
                comp_results = result['results']
                summary = comp_results['summary']

                print(f"\n  {Colors.BLUE}{result['table_a']}{Colors.RESET} vs {Colors.BLUE}{result['table_b']}{Colors.RESET}")
                print(f"    Issues found: {summary['issues_found']}")
                for issue in summary['issues'][:3]:
                    print(f"      - {issue}")
                if len(summary['issues']) > 3:
                    print(f"      ... and {len(summary['issues']) - 3} more")

        if identical:
            print(f"\n{Colors.GREEN}{Colors.BOLD}Identical tables: {len(identical)}{Colors.RESET}")

        print(f"\n{Colors.CYAN}{'=' * 80}{Colors.RESET}\n")


def parse_table_pairs(args) -> List[Tuple[str, str]]:
    """
    Parse table pairs from various sources.

    Args:
        args: Parsed command-line arguments

    Returns:
        List of (table_a, table_b) tuples
    """
    pairs = []

    # From command line arguments
    if args.table_a and args.table_b:
        pairs.append((args.table_a, args.table_b))

    # From file
    if args.pairs_file:
        try:
            with open(args.pairs_file, 'r') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#'):
                        if ':' in line:
                            table_a, table_b = line.split(':', 1)
                            pairs.append((table_a.strip(), table_b.strip()))
        except Exception as e:
            print(f"{Colors.RED}Error reading pairs file: {str(e)}{Colors.RESET}", file=sys.stderr)
            sys.exit(1)

    # From stdin
    if not sys.stdin.isatty() and not args.table_a:
        for line in sys.stdin:
            line = line.strip()
            if line and not line.startswith('#'):
                if ':' in line:
                    table_a, table_b = line.split(':', 1)
                    pairs.append((table_a.strip(), table_b.strip()))

    return pairs


def main():
    parser = argparse.ArgumentParser(
        description="Detailed comparison of two BigQuery tables",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__
    )
    parser.add_argument("table_a", nargs='?', help="First table ID (project.dataset.table)")
    parser.add_argument("table_b", nargs='?', help="Second table ID (project.dataset.table)")
    parser.add_argument("--format", choices=["text", "json"], default="text",
                       help="Output format (default: text)")
    parser.add_argument("--sample-size", type=int, default=100,
                       help="Number of rows to sample (default: 100)")
    parser.add_argument("--skip-stats", action="store_true",
                       help="Skip statistical comparisons")
    parser.add_argument("--skip-samples", action="store_true",
                       help="Skip sample data comparison")
    parser.add_argument("--parallel", type=int, default=4,
                       help="Number of parallel workers for batch comparison (default: 4)")
    parser.add_argument("--progress", action="store_true",
                       help="Show progress bar during batch comparison")
    parser.add_argument("--pairs-file", type=str,
                       help="Read table pairs from file (one pair per line, format: table_a:table_b)")

    args = parser.parse_args()

    # Parse table pairs
    table_pairs = parse_table_pairs(args)

    if not table_pairs:
        print(f"{Colors.RED}Error: No table pairs provided{Colors.RESET}", file=sys.stderr)
        print(f"{Colors.YELLOW}Provide pairs via arguments, --pairs-file, or stdin{Colors.RESET}",
              file=sys.stderr)
        sys.exit(1)

    # Validate parallel workers
    max_workers = cpu_count() * 2
    if args.parallel < 1:
        args.parallel = 1
    elif args.parallel > max_workers:
        print(f"{Colors.YELLOW}Warning: Limiting workers to {max_workers} (system max){Colors.RESET}",
              file=sys.stderr)
        args.parallel = max_workers

    # Check for rich library if progress requested
    if args.progress and not RICH_AVAILABLE:
        print(f"{Colors.YELLOW}Warning: rich library not installed. Install with: pip install rich{Colors.RESET}",
              file=sys.stderr)
        print(f"{Colors.YELLOW}Continuing without progress bar...{Colors.RESET}", file=sys.stderr)
        args.progress = False

    # Initialize BigQuery client
    try:
        client = bigquery.Client()
    except Exception as e:
        print(f"{Colors.RED}Error initializing BigQuery client: {str(e)}{Colors.RESET}",
              file=sys.stderr)
        sys.exit(1)

    if len(table_pairs) > 1:
        # Batch mode with parallel processing
        print(f"{Colors.CYAN}Comparing {len(table_pairs)} pairs with {args.parallel} workers{Colors.RESET}",
              file=sys.stderr)

        results = compare_batch_pairs(
            table_pairs,
            sample_size=args.sample_size,
            skip_stats=args.skip_stats,
            skip_samples=args.skip_samples,
            num_workers=args.parallel,
            show_progress=args.progress
        )

        # Print batch summary
        print_batch_summary(results, args.format)

        # Exit with error if any failed or different
        if any(not r['success'] or not r.get('identical', False) for r in results):
            sys.exit(1)
    else:
        # Single pair mode
        table_a, table_b = table_pairs[0]

        # Run comparison
        comparer = TableComparison(
            client,
            table_a,
            table_b,
            sample_size=args.sample_size,
            skip_stats=args.skip_stats,
            skip_samples=args.skip_samples
        )
        results = comparer.run_comparison()

        # Print report
        if args.format == "json":
            print_json_report(table_a, table_b, results)
        else:
            print_text_report(table_a, table_b, results)

        # Exit with status code
        if not results['summary']['identical']:
            sys.exit(1)
        else:
            sys.exit(0)


if __name__ == "__main__":
    main()
