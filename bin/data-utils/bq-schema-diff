#!/usr/bin/env python3
"""
bq-schema-diff - Compare schemas of two BigQuery tables

Usage:
  bq-schema-diff <table_a> <table_b> [options]
  bq-schema-diff --pairs-file=<file> [options]
  echo "table1:table2" | bq-schema-diff --parallel 2

Arguments:
  table_a    First table ID (format: project.dataset.table)
  table_b    Second table ID (format: project.dataset.table)

Options:
  --format=<format>   Output format: text, json (default: text)
  --no-cache          Disable metadata caching and force fresh API calls
  --parallel=<n>      Number of parallel workers for batch comparison (default: 4)
  --progress          Show progress bar during batch comparison
  --pairs-file=<file> Read table pairs from file (one pair per line, format: table_a:table_b)
  --help, -h          Show this help message

Examples:
  bq-schema-diff project.dataset.table_v1 project.dataset.table_v2
  bq-schema-diff myproject.staging.users myproject.prod.users --format=json
  bq-schema-diff project.dataset.table_v1 project.dataset.table_v2 --no-cache
  bq-schema-diff --parallel 2 --pairs-file=table_pairs.txt
  echo -e "dev.t1:prod.t1\ndev.t2:prod.t2" | bq-schema-diff --parallel 2 --progress
"""

import sys
import json
import argparse
from typing import Dict, List, Set, Tuple, Optional
from pathlib import Path
from google.cloud import bigquery
from multiprocessing import Pool, cpu_count
from functools import partial

# Add lib directory to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent.parent / "lib"))

try:
    from bq_cache import BQMetadataCache
    CACHE_AVAILABLE = True
except ImportError:
    CACHE_AVAILABLE = False

try:
    from rich.progress import Progress, SpinnerColumn, BarColumn, TextColumn, TimeRemainingColumn
    from rich.console import Console
    RICH_AVAILABLE = True
except ImportError:
    RICH_AVAILABLE = False

try:
    from common_errors import (
        validate_table_id,
        handle_api_error,
        error_context,
        log_error,
    )
    ERROR_HANDLING_AVAILABLE = True
except ImportError:
    ERROR_HANDLING_AVAILABLE = False


class Colors:
    """ANSI color codes for terminal output"""
    RED = '\033[0;31m'
    GREEN = '\033[0;32m'
    YELLOW = '\033[1;33m'
    BLUE = '\033[0;34m'
    CYAN = '\033[0;36m'
    RESET = '\033[0m'
    BOLD = '\033[1m'


def get_table_schema(client: bigquery.Client, table_id: str, cache: Optional[BQMetadataCache] = None) -> Dict[str, str]:
    """
    Get the schema of a BigQuery table as a dictionary.

    Args:
        client: BigQuery client
        table_id: Full table ID (project.dataset.table)
        cache: Optional BQMetadataCache instance

    Returns:
        Dictionary mapping field names to field types
    """
    try:
        if cache:
            # Get schema from cache
            schema_list = cache.get_cached_schema(client, table_id)
            schema = {}
            for field in schema_list:
                # Handle nested fields
                if field['type'] == 'RECORD' and 'fields' in field:
                    nested_fields = []
                    for nested_field in field['fields']:
                        nested_fields.append(f"{nested_field['name']}:{nested_field['type']}")
                    schema[field['name']] = f"RECORD<{', '.join(nested_fields)}>"
                else:
                    mode = f" ({field['mode']})" if field['mode'] != 'NULLABLE' else ""
                    schema[field['name']] = f"{field['type']}{mode}"
            return schema
        else:
            table = client.get_table(table_id)
            schema = {}
            for field in table.schema:
                # Handle nested fields
                if field.field_type == 'RECORD':
                    nested_fields = []
                    for nested_field in field.fields:
                        nested_fields.append(f"{nested_field.name}:{nested_field.field_type}")
                    schema[field.name] = f"RECORD<{', '.join(nested_fields)}>"
                else:
                    mode = f" ({field.mode})" if field.mode != 'NULLABLE' else ""
                    schema[field.name] = f"{field.field_type}{mode}"
            return schema
    except Exception as e:
        if ERROR_HANDLING_AVAILABLE:
            log_error(e, context={"table_id": table_id, "operation": "get_table_schema"})
            raise handle_api_error(e, resource_type="table") from e
        else:
            print(f"{Colors.RED}Error fetching schema for {table_id}: {str(e)}{Colors.RESET}", file=sys.stderr)
            sys.exit(1)


def compare_schemas(schema_a: Dict[str, str], schema_b: Dict[str, str]) -> Tuple[Set[str], Set[str], Dict[str, Tuple[str, str]]]:
    """
    Compare two schemas and identify differences.

    Args:
        schema_a: Schema of first table
        schema_b: Schema of second table

    Returns:
        Tuple of (fields only in A, fields only in B, fields with type changes)
    """
    keys_a = set(schema_a.keys())
    keys_b = set(schema_b.keys())

    only_in_a = keys_a - keys_b
    only_in_b = keys_b - keys_a

    type_changes = {}
    for key in keys_a & keys_b:
        if schema_a[key] != schema_b[key]:
            type_changes[key] = (schema_a[key], schema_b[key])

    return only_in_a, only_in_b, type_changes


def print_text_report(table_a: str, table_b: str, only_in_a: Set[str], only_in_b: Set[str],
                     type_changes: Dict[str, Tuple[str, str]], schema_a: Dict[str, str],
                     schema_b: Dict[str, str]):
    """Print a formatted text report of schema differences"""

    print(f"\n{Colors.CYAN}{Colors.BOLD}Schema Comparison{Colors.RESET}")
    print(f"{Colors.BLUE}Table A:{Colors.RESET} {table_a}")
    print(f"{Colors.BLUE}Table B:{Colors.RESET} {table_b}")
    print("=" * 80)

    # Fields only in A
    if only_in_a:
        print(f"\n{Colors.RED}{Colors.BOLD}Fields only in Table A ({len(only_in_a)}):{Colors.RESET}")
        for field in sorted(only_in_a):
            print(f"  {Colors.RED}−{Colors.RESET} {field}: {schema_a[field]}")

    # Fields only in B
    if only_in_b:
        print(f"\n{Colors.GREEN}{Colors.BOLD}Fields only in Table B ({len(only_in_b)}):{Colors.RESET}")
        for field in sorted(only_in_b):
            print(f"  {Colors.GREEN}+{Colors.RESET} {field}: {schema_b[field]}")

    # Type changes
    if type_changes:
        print(f"\n{Colors.YELLOW}{Colors.BOLD}Fields with type changes ({len(type_changes)}):{Colors.RESET}")
        for field, (type_a, type_b) in sorted(type_changes.items()):
            print(f"  {Colors.YELLOW}~{Colors.RESET} {field}:")
            print(f"    {Colors.RED}A:{Colors.RESET} {type_a}")
            print(f"    {Colors.GREEN}B:{Colors.RESET} {type_b}")

    # Summary
    print(f"\n{Colors.CYAN}{Colors.BOLD}Summary{Colors.RESET}")
    if not only_in_a and not only_in_b and not type_changes:
        print(f"{Colors.GREEN}✓ Schemas are identical{Colors.RESET}")
    else:
        print(f"  Fields only in A: {len(only_in_a)}")
        print(f"  Fields only in B: {len(only_in_b)}")
        print(f"  Type changes: {len(type_changes)}")
        print(f"  {Colors.YELLOW}⚠ Schemas differ{Colors.RESET}")
    print("=" * 80)


def print_json_report(table_a: str, table_b: str, only_in_a: Set[str], only_in_b: Set[str],
                     type_changes: Dict[str, Tuple[str, str]], schema_a: Dict[str, str],
                     schema_b: Dict[str, str]):
    """Print a JSON report of schema differences"""

    report = {
        "table_a": table_a,
        "table_b": table_b,
        "only_in_a": [{"field": field, "type": schema_a[field]} for field in sorted(only_in_a)],
        "only_in_b": [{"field": field, "type": schema_b[field]} for field in sorted(only_in_b)],
        "type_changes": [
            {
                "field": field,
                "type_a": type_a,
                "type_b": type_b
            }
            for field, (type_a, type_b) in sorted(type_changes.items())
        ],
        "identical": not only_in_a and not only_in_b and not type_changes,
        "summary": {
            "fields_only_in_a": len(only_in_a),
            "fields_only_in_b": len(only_in_b),
            "type_changes": len(type_changes)
        }
    }

    print(json.dumps(report, indent=2))


def compare_single_pair(table_pair: Tuple[str, str], use_cache: bool) -> Dict:
    """
    Compare a single pair of tables (wrapper for parallel execution).

    Args:
        table_pair: Tuple of (table_a, table_b)
        use_cache: Whether to use metadata cache

    Returns:
        Comparison result dictionary
    """
    table_a, table_b = table_pair

    try:
        # Create new client for this process
        client = bigquery.Client()

        # Initialize cache if enabled
        cache = None
        if use_cache and CACHE_AVAILABLE:
            cache = BQMetadataCache()

        # Get schemas
        schema_a = get_table_schema(client, table_a, cache)
        schema_b = get_table_schema(client, table_b, cache)

        # Compare schemas
        only_in_a, only_in_b, type_changes = compare_schemas(schema_a, schema_b)

        return {
            'table_a': table_a,
            'table_b': table_b,
            'success': True,
            'only_in_a': sorted(only_in_a),
            'only_in_b': sorted(only_in_b),
            'type_changes': type_changes,
            'schema_a': schema_a,
            'schema_b': schema_b,
            'identical': len(only_in_a) == 0 and len(only_in_b) == 0 and len(type_changes) == 0
        }
    except Exception as e:
        return {
            'table_a': table_a,
            'table_b': table_b,
            'success': False,
            'error': str(e)
        }


def compare_batch_pairs(table_pairs: List[Tuple[str, str]], use_cache: bool,
                        num_workers: int, show_progress: bool) -> List[Dict]:
    """
    Compare multiple table pairs in parallel.

    Args:
        table_pairs: List of (table_a, table_b) tuples
        use_cache: Whether to use metadata cache
        num_workers: Number of parallel workers
        show_progress: Whether to show progress bar

    Returns:
        List of comparison results
    """
    # Create partial function with fixed arguments
    compare_func = partial(compare_single_pair, use_cache=use_cache)

    results = []

    if show_progress and RICH_AVAILABLE:
        console = Console()
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
            TimeRemainingColumn(),
            console=console
        ) as progress:
            task = progress.add_task(f"Comparing {len(table_pairs)} pairs", total=len(table_pairs))

            with Pool(num_workers) as pool:
                for result in pool.imap_unordered(compare_func, table_pairs):
                    results.append(result)
                    if result['success']:
                        status = "✓" if result['identical'] else "≠"
                    else:
                        status = "✗"
                    progress.console.print(f"{status} {result['table_a']} vs {result['table_b']}")
                    progress.advance(task)
    else:
        # No progress bar
        with Pool(num_workers) as pool:
            results = list(pool.map(compare_func, table_pairs))

    return results


def print_batch_summary(results: List[Dict], output_format: str):
    """
    Print summary of batch comparison results.

    Args:
        results: List of comparison results
        output_format: Output format (text, json)
    """
    successful = [r for r in results if r['success']]
    failed = [r for r in results if not r['success']]
    identical = [r for r in successful if r['identical']]
    different = [r for r in successful if not r['identical']]

    if output_format == "json":
        # JSON output with all comparisons
        output = {
            'batch_summary': {
                'total_pairs': len(results),
                'successful': len(successful),
                'failed': len(failed),
                'identical': len(identical),
                'different': len(different)
            },
            'comparisons': [
                {
                    'table_a': r['table_a'],
                    'table_b': r['table_b'],
                    'identical': r.get('identical', False),
                    'only_in_a': r.get('only_in_a', []),
                    'only_in_b': r.get('only_in_b', []),
                    'type_changes': r.get('type_changes', {}),
                    'summary': {
                        'fields_only_in_a': len(r.get('only_in_a', [])),
                        'fields_only_in_b': len(r.get('only_in_b', [])),
                        'type_changes': len(r.get('type_changes', {}))
                    }
                } for r in successful
            ],
            'errors': [
                {
                    'table_a': r['table_a'],
                    'table_b': r['table_b'],
                    'error': r.get('error')
                } for r in failed
            ]
        }
        print(json.dumps(output, indent=2))
    else:
        # Text summary
        print(f"\n{Colors.CYAN}{Colors.BOLD}{'=' * 80}{Colors.RESET}")
        print(f"{Colors.CYAN}{Colors.BOLD}Batch Schema Comparison Summary{Colors.RESET}")
        print(f"{Colors.CYAN}{Colors.BOLD}{'=' * 80}{Colors.RESET}\n")

        print(f"{Colors.BOLD}Results:{Colors.RESET}")
        print(f"  Total pairs: {len(results)}")
        print(f"  {Colors.GREEN}Successful: {len(successful)}{Colors.RESET}")
        print(f"  {Colors.GREEN}Identical: {len(identical)}{Colors.RESET}")
        print(f"  {Colors.YELLOW}Different: {len(different)}{Colors.RESET}")
        if failed:
            print(f"  {Colors.RED}Failed: {len(failed)}{Colors.RESET}")

        if failed:
            print(f"\n{Colors.RED}{Colors.BOLD}Failed comparisons:{Colors.RESET}")
            for result in failed:
                print(f"  {Colors.RED}✗{Colors.RESET} {result['table_a']} vs {result['table_b']}: {result['error']}")

        if different:
            print(f"\n{Colors.YELLOW}{Colors.BOLD}Different schemas:{Colors.RESET}")
            for result in different:
                only_in_a = set(result['only_in_a'])
                only_in_b = set(result['only_in_b'])
                type_changes = result['type_changes']

                print(f"\n  {Colors.BLUE}{result['table_a']}{Colors.RESET} vs {Colors.BLUE}{result['table_b']}{Colors.RESET}")
                if only_in_a:
                    print(f"    Only in A: {len(only_in_a)} fields")
                if only_in_b:
                    print(f"    Only in B: {len(only_in_b)} fields")
                if type_changes:
                    print(f"    Type changes: {len(type_changes)} fields")

        if identical:
            print(f"\n{Colors.GREEN}{Colors.BOLD}Identical schemas: {len(identical)}{Colors.RESET}")

        print(f"\n{Colors.CYAN}{'=' * 80}{Colors.RESET}\n")


def parse_table_pairs(args) -> List[Tuple[str, str]]:
    """
    Parse table pairs from various sources.

    Args:
        args: Parsed command-line arguments

    Returns:
        List of (table_a, table_b) tuples
    """
    pairs = []

    # From command line arguments
    if args.table_a and args.table_b:
        pairs.append((args.table_a, args.table_b))

    # From file
    if args.pairs_file:
        try:
            with open(args.pairs_file, 'r') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#'):
                        if ':' in line:
                            table_a, table_b = line.split(':', 1)
                            pairs.append((table_a.strip(), table_b.strip()))
        except Exception as e:
            print(f"{Colors.RED}Error reading pairs file: {str(e)}{Colors.RESET}", file=sys.stderr)
            sys.exit(1)

    # From stdin
    if not sys.stdin.isatty() and not args.table_a:
        for line in sys.stdin:
            line = line.strip()
            if line and not line.startswith('#'):
                if ':' in line:
                    table_a, table_b = line.split(':', 1)
                    pairs.append((table_a.strip(), table_b.strip()))

    return pairs


def main():
    parser = argparse.ArgumentParser(
        description="Compare schemas of two BigQuery tables",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__
    )
    parser.add_argument("table_a", nargs='?', help="First table ID (project.dataset.table)")
    parser.add_argument("table_b", nargs='?', help="Second table ID (project.dataset.table)")
    parser.add_argument("--format", choices=["text", "json"], default="text",
                       help="Output format (default: text)")
    parser.add_argument("--no-cache", action="store_true",
                       help="Disable metadata caching and force fresh API calls")
    parser.add_argument("--parallel", type=int, default=4,
                       help="Number of parallel workers for batch comparison (default: 4)")
    parser.add_argument("--progress", action="store_true",
                       help="Show progress bar during batch comparison")
    parser.add_argument("--pairs-file", type=str,
                       help="Read table pairs from file (one pair per line, format: table_a:table_b)")

    args = parser.parse_args()

    # Parse table pairs
    table_pairs = parse_table_pairs(args)

    if not table_pairs:
        print(f"{Colors.RED}Error: No table pairs provided{Colors.RESET}", file=sys.stderr)
        print(f"{Colors.YELLOW}Provide pairs via arguments, --pairs-file, or stdin{Colors.RESET}",
              file=sys.stderr)
        sys.exit(1)

    # Validate parallel workers
    max_workers = cpu_count() * 2
    if args.parallel < 1:
        args.parallel = 1
    elif args.parallel > max_workers:
        print(f"{Colors.YELLOW}Warning: Limiting workers to {max_workers} (system max){Colors.RESET}",
              file=sys.stderr)
        args.parallel = max_workers

    # Check for rich library if progress requested
    if args.progress and not RICH_AVAILABLE:
        print(f"{Colors.YELLOW}Warning: rich library not installed. Install with: pip install rich{Colors.RESET}",
              file=sys.stderr)
        print(f"{Colors.YELLOW}Continuing without progress bar...{Colors.RESET}", file=sys.stderr)
        args.progress = False

    # Initialize BigQuery client
    try:
        client = bigquery.Client()
    except Exception as e:
        print(f"{Colors.RED}Error initializing BigQuery client: {str(e)}{Colors.RESET}",
              file=sys.stderr)
        sys.exit(1)

    use_cache = not args.no_cache

    if len(table_pairs) > 1:
        # Batch mode with parallel processing
        print(f"{Colors.CYAN}Comparing {len(table_pairs)} pairs with {args.parallel} workers{Colors.RESET}",
              file=sys.stderr)

        results = compare_batch_pairs(
            table_pairs,
            use_cache=use_cache,
            num_workers=args.parallel,
            show_progress=args.progress
        )

        # Print batch summary
        print_batch_summary(results, args.format)

        # Exit with error if any failed or different
        if any(not r['success'] or not r.get('identical', False) for r in results):
            sys.exit(1)
    else:
        # Single pair mode
        table_a, table_b = table_pairs[0]

        # Initialize cache if enabled and available
        cache = None
        if use_cache and CACHE_AVAILABLE:
            cache = BQMetadataCache()

        # Get schemas
        schema_a = get_table_schema(client, table_a, cache)
        schema_b = get_table_schema(client, table_b, cache)

        # Compare schemas
        only_in_a, only_in_b, type_changes = compare_schemas(schema_a, schema_b)

        # Print report
        if args.format == "json":
            print_json_report(table_a, table_b, only_in_a, only_in_b, type_changes, schema_a, schema_b)
        else:
            print_text_report(table_a, table_b, only_in_a, only_in_b, type_changes, schema_a, schema_b)

        # Exit with status code
        if only_in_a or only_in_b or type_changes:
            sys.exit(1)
        else:
            sys.exit(0)


if __name__ == "__main__":
    main()
