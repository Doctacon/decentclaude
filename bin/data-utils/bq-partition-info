#!/usr/bin/env python3
"""
bq-partition-info - Analyze BigQuery table partitioning details

Usage:
  bq-partition-info <table_id> [options]

Arguments:
  table_id   Table ID (format: project.dataset.table)

Options:
  --top=<n>          Show top N partitions by size (default: 10)
  --format=<format>  Output format: text, json (default: text)
  --no-cache         Disable metadata caching and force fresh API calls
  --help, -h         Show this help message

Examples:
  bq-partition-info project.dataset.events
  bq-partition-info project.dataset.events --top=20
  bq-partition-info project.dataset.events --format=json
  bq-partition-info project.dataset.events --no-cache
"""

import sys
import json
import argparse
from datetime import datetime
from pathlib import Path
from typing import Optional
from google.cloud import bigquery

# Add lib directory to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent.parent / "lib"))

try:
    from bq_cache import BQMetadataCache
    CACHE_AVAILABLE = True
except ImportError:
    CACHE_AVAILABLE = False


class Colors:
    """ANSI color codes for terminal output"""
    RED = '\033[0;31m'
    GREEN = '\033[0;32m'
    YELLOW = '\033[1;33m'
    BLUE = '\033[0;34m'
    CYAN = '\033[0;36m'
    RESET = '\033[0m'
    BOLD = '\033[1m'


def format_bytes(bytes_value: int) -> str:
    """Format bytes into human-readable string"""
    for unit in ['B', 'KB', 'MB', 'GB', 'TB', 'PB']:
        if bytes_value < 1024.0:
            return f"{bytes_value:.2f} {unit}"
        bytes_value /= 1024.0
    return f"{bytes_value:.2f} EB"


def get_partition_info(client: bigquery.Client, table_id: str, top_n: int = 10, cache: Optional[BQMetadataCache] = None) -> dict:
    """
    Get detailed partitioning information for a BigQuery table.

    Args:
        client: BigQuery client
        table_id: Full table ID (project.dataset.table)
        top_n: Number of top partitions to show
        cache: Optional BQMetadataCache instance

    Returns:
        Dictionary with partition information
    """
    try:
        # Parse table ID
        parts = table_id.split('.')
        if len(parts) != 3:
            raise ValueError("Table ID must be in format: project.dataset.table")
        project, dataset, table_name = parts

        if cache:
            # Get partition info from cache
            partition_info = cache.get_cached_partition_info(client, table_id)
            metadata = cache.get_cached_table_metadata(client, table_id)

            result = {
                "table_id": table_id,
                "is_partitioned": partition_info["is_partitioned"],
                "partitioning_type": partition_info["partitioning_type"],
                "partition_field": partition_info["partition_field"],
                "partition_expiration_days": partition_info["partition_expiration_days"],
                "require_partition_filter": partition_info["require_partition_filter"],
                "clustering_fields": partition_info["clustering_fields"],
                "total_rows": metadata["num_rows"],
                "total_bytes": metadata["num_bytes"],
                "partitions": []
            }
        else:
            # Get table metadata directly
            table = client.get_table(table_id)

            # Check if table is partitioned
            is_partitioned = table.time_partitioning is not None or table.range_partitioning is not None

            result = {
                "table_id": table_id,
                "is_partitioned": is_partitioned,
                "partitioning_type": None,
                "partition_field": None,
                "partition_expiration_days": None,
                "require_partition_filter": None,
                "clustering_fields": table.clustering_fields,
                "total_rows": table.num_rows,
                "total_bytes": table.num_bytes,
                "partitions": []
            }

            if is_partitioned:
                # Get partitioning details
                if table.time_partitioning:
                    result["partitioning_type"] = f"TIME ({table.time_partitioning.type_})"
                    result["partition_field"] = table.time_partitioning.field or "_PARTITIONTIME"
                    result["partition_expiration_days"] = table.time_partitioning.expiration_ms / (1000 * 60 * 60 * 24) if table.time_partitioning.expiration_ms else None
                    result["require_partition_filter"] = table.time_partitioning.require_partition_filter

                elif table.range_partitioning:
                    result["partitioning_type"] = "RANGE"
                    result["partition_field"] = table.range_partitioning.field
                    result["require_partition_filter"] = table.require_partition_filter

        if not result["is_partitioned"]:
            return result

        # Query partition metadata from INFORMATION_SCHEMA
        query = f"""
        SELECT
          partition_id,
          total_rows,
          total_logical_bytes,
          total_billable_bytes,
          last_modified_time
        FROM `{project}.{dataset}.INFORMATION_SCHEMA.PARTITIONS`
        WHERE table_name = '{table_name}'
          AND partition_id IS NOT NULL
          AND partition_id != '__NULL__'
        ORDER BY total_logical_bytes DESC
        LIMIT {top_n}
        """

        query_job = client.query(query)
        partitions = []

        for row in query_job:
            partitions.append({
                "partition_id": row.partition_id,
                "total_rows": row.total_rows,
                "total_logical_bytes": row.total_logical_bytes,
                "total_billable_bytes": row.total_billable_bytes,
                "last_modified_time": row.last_modified_time.isoformat() if row.last_modified_time else None
            })

        result["partitions"] = partitions
        result["partition_count"] = len(partitions)

        return result

    except Exception as e:
        print(f"{Colors.RED}Error fetching partition info for {table_id}: {str(e)}{Colors.RESET}", file=sys.stderr)
        sys.exit(1)


def print_text_report(result: dict):
    """Print a formatted text report of partition information"""

    print(f"\n{Colors.CYAN}{Colors.BOLD}BigQuery Partition Analysis{Colors.RESET}")
    print(f"{Colors.BLUE}Table:{Colors.RESET} {result['table_id']}")
    print("=" * 80)

    # Partitioning status
    if result['is_partitioned']:
        print(f"\n{Colors.GREEN}✓ Table is partitioned{Colors.RESET}")
    else:
        print(f"\n{Colors.YELLOW}⚠ Table is NOT partitioned{Colors.RESET}")
        print("\n" + "=" * 80)
        return

    # Partitioning configuration
    print(f"\n{Colors.BOLD}Partitioning Configuration:{Colors.RESET}")
    print(f"  Type:                    {result['partitioning_type']}")
    print(f"  Field:                   {result['partition_field']}")
    print(f"  Expiration:              {result['partition_expiration_days']} days" if result['partition_expiration_days'] else "  Expiration:              None")
    print(f"  Require partition filter: {result['require_partition_filter']}")

    # Clustering
    if result['clustering_fields']:
        print(f"  Clustering fields:       {', '.join(result['clustering_fields'])}")

    # Table statistics
    print(f"\n{Colors.BOLD}Table Statistics:{Colors.RESET}")
    print(f"  Total rows:    {result['total_rows']:,}")
    print(f"  Total size:    {format_bytes(result['total_bytes'])}")

    # Top partitions
    if result['partitions']:
        print(f"\n{Colors.BOLD}Top {len(result['partitions'])} Partitions by Size:{Colors.RESET}")
        print(f"\n  {'Partition ID':<20} {'Rows':>15} {'Size':>12} {'Billable':>12} {'Modified':<20}")
        print(f"  {'-' * 20} {'-' * 15} {'-' * 12} {'-' * 12} {'-' * 20}")

        for partition in result['partitions']:
            partition_id = partition['partition_id']
            rows = f"{partition['total_rows']:,}" if partition['total_rows'] else "0"
            size = format_bytes(partition['total_logical_bytes']) if partition['total_logical_bytes'] else "0 B"
            billable = format_bytes(partition['total_billable_bytes']) if partition['total_billable_bytes'] else "0 B"
            modified = partition['last_modified_time'][:19] if partition['last_modified_time'] else "N/A"

            # Color code based on size
            if partition['total_logical_bytes'] and partition['total_logical_bytes'] > 1024**3:  # > 1 GB
                color = Colors.YELLOW
            else:
                color = Colors.RESET

            print(f"  {color}{partition_id:<20}{Colors.RESET} {rows:>15} {size:>12} {billable:>12} {modified:<20}")

    print("\n" + "=" * 80)


def print_json_report(result: dict):
    """Print a JSON report of partition information"""

    # Add human-readable fields
    output = result.copy()
    output['total_bytes_human'] = format_bytes(result['total_bytes'])

    for partition in output['partitions']:
        partition['total_logical_bytes_human'] = format_bytes(partition['total_logical_bytes']) if partition['total_logical_bytes'] else "0 B"
        partition['total_billable_bytes_human'] = format_bytes(partition['total_billable_bytes']) if partition['total_billable_bytes'] else "0 B"

    print(json.dumps(output, indent=2))


def main():
    parser = argparse.ArgumentParser(
        description="Analyze BigQuery table partitioning details",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__
    )
    parser.add_argument("table_id", help="Table ID (project.dataset.table)")
    parser.add_argument("--top", type=int, default=10,
                       help="Show top N partitions by size (default: 10)")
    parser.add_argument("--format", choices=["text", "json"], default="text",
                       help="Output format (default: text)")
    parser.add_argument("--no-cache", action="store_true",
                       help="Disable metadata caching and force fresh API calls")

    args = parser.parse_args()

    # Initialize BigQuery client
    client = bigquery.Client()

    # Initialize cache if enabled and available
    cache = None
    if not args.no_cache and CACHE_AVAILABLE:
        cache = BQMetadataCache()

    # Get partition information
    result = get_partition_info(client, args.table_id, args.top, cache)

    # Print report
    if args.format == "json":
        print_json_report(result)
    else:
        print_text_report(result)


if __name__ == "__main__":
    main()
