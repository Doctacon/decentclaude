#!/usr/bin/env python3
"""
sf-warehouse-monitor - Monitor Snowflake warehouse usage and costs

Usage:
  sf-warehouse-monitor [options]
  sf-warehouse-monitor --warehouse=<name> [options]

Options:
  --warehouse=<name>  Monitor specific warehouse (default: all warehouses)
  --days=<n>          Number of days to analyze (default: 7, max: 30)
  --format=<format>   Output format: text, json (default: text)
  --top=<n>           Show top N queries by credits (default: 10)
  --help, -h          Show this help message

Examples:
  sf-warehouse-monitor
  sf-warehouse-monitor --warehouse=COMPUTE_WH --days=30
  sf-warehouse-monitor --days=7 --format=json
  sf-warehouse-monitor --warehouse=ANALYTICS_WH --top=20

Description:
  Monitors warehouse usage including:
  - Total credits consumed
  - Query count and average duration
  - Top queries by credit consumption
  - Warehouse utilization over time
  - Cost breakdown by warehouse
"""

import sys
import json
import argparse
from datetime import datetime, timedelta
import snowflake.connector
import os
from collections import defaultdict


class Colors:
    """ANSI color codes for terminal output"""
    RED = '\033[0;31m'
    GREEN = '\033[0;32m'
    YELLOW = '\033[1;33m'
    BLUE = '\033[0;34m'
    CYAN = '\033[0;36m'
    RESET = '\033[0m'
    BOLD = '\033[1m'


# Average credit cost (varies by region and edition)
DEFAULT_CREDIT_COST_USD = 2.50


def get_snowflake_connection():
    """Create a Snowflake connection using environment variables."""
    try:
        conn_params = {
            'account': os.environ.get('SNOWFLAKE_ACCOUNT'),
            'user': os.environ.get('SNOWFLAKE_USER'),
        }

        # Authentication
        if os.environ.get('SNOWFLAKE_AUTHENTICATOR'):
            conn_params['authenticator'] = os.environ['SNOWFLAKE_AUTHENTICATOR']
        else:
            conn_params['password'] = os.environ.get('SNOWFLAKE_PASSWORD')

        # Optional parameters
        if os.environ.get('SNOWFLAKE_WAREHOUSE'):
            conn_params['warehouse'] = os.environ['SNOWFLAKE_WAREHOUSE']
        if os.environ.get('SNOWFLAKE_ROLE'):
            conn_params['role'] = os.environ['SNOWFLAKE_ROLE']

        return snowflake.connector.connect(**conn_params)
    except Exception as e:
        print(f"{Colors.RED}Error connecting to Snowflake: {str(e)}{Colors.RESET}", file=sys.stderr)
        print(f"{Colors.YELLOW}Make sure SNOWFLAKE_ACCOUNT, SNOWFLAKE_USER, and SNOWFLAKE_PASSWORD are set{Colors.RESET}", file=sys.stderr)
        sys.exit(1)


def get_warehouse_usage(conn, warehouse_name: str = None, days: int = 7, top_n: int = 10) -> dict:
    """
    Get warehouse usage statistics from Snowflake.

    Args:
        conn: Snowflake connection
        warehouse_name: Specific warehouse name (None for all)
        days: Number of days to analyze
        top_n: Number of top queries to return

    Returns:
        Dictionary with usage statistics
    """
    try:
        cursor = conn.cursor()

        # Calculate date range
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days)

        # Build warehouse filter
        warehouse_filter = ""
        if warehouse_name:
            warehouse_filter = f"AND WAREHOUSE_NAME = '{warehouse_name.upper()}'"

        # Query for overall warehouse statistics
        warehouse_query = f"""
        SELECT
            WAREHOUSE_NAME,
            COUNT(*) as QUERY_COUNT,
            SUM(CREDITS_USED_CLOUD_SERVICES) as CLOUD_SERVICES_CREDITS,
            SUM(CREDITS_USED_COMPUTE) as COMPUTE_CREDITS,
            SUM(TOTAL_ELAPSED_TIME) / 1000 as TOTAL_ELAPSED_SECONDS,
            AVG(TOTAL_ELAPSED_TIME) / 1000 as AVG_ELAPSED_SECONDS,
            MAX(TOTAL_ELAPSED_TIME) / 1000 as MAX_ELAPSED_SECONDS,
            SUM(BYTES_SCANNED) as TOTAL_BYTES_SCANNED,
            SUM(ROWS_PRODUCED) as TOTAL_ROWS_PRODUCED
        FROM SNOWFLAKE.ACCOUNT_USAGE.QUERY_HISTORY
        WHERE START_TIME >= '{start_date.strftime('%Y-%m-%d')}'
          AND START_TIME < '{end_date.strftime('%Y-%m-%d')}'
          AND WAREHOUSE_NAME IS NOT NULL
          {warehouse_filter}
        GROUP BY WAREHOUSE_NAME
        ORDER BY COMPUTE_CREDITS DESC
        """

        cursor.execute(warehouse_query)
        warehouse_stats = cursor.fetchall()

        # Query for top queries by credit consumption
        top_queries_query = f"""
        SELECT
            QUERY_ID,
            QUERY_TEXT,
            WAREHOUSE_NAME,
            USER_NAME,
            START_TIME,
            TOTAL_ELAPSED_TIME / 1000 as ELAPSED_SECONDS,
            CREDITS_USED_CLOUD_SERVICES,
            CREDITS_USED_COMPUTE,
            BYTES_SCANNED,
            ROWS_PRODUCED
        FROM SNOWFLAKE.ACCOUNT_USAGE.QUERY_HISTORY
        WHERE START_TIME >= '{start_date.strftime('%Y-%m-%d')}'
          AND START_TIME < '{end_date.strftime('%Y-%m-%d')}'
          AND WAREHOUSE_NAME IS NOT NULL
          {warehouse_filter}
        ORDER BY CREDITS_USED_COMPUTE DESC
        LIMIT {top_n}
        """

        cursor.execute(top_queries_query)
        top_queries = cursor.fetchall()

        # Query for daily credit usage
        daily_query = f"""
        SELECT
            DATE_TRUNC('DAY', START_TIME) as DAY,
            WAREHOUSE_NAME,
            SUM(CREDITS_USED_COMPUTE) as COMPUTE_CREDITS,
            COUNT(*) as QUERY_COUNT
        FROM SNOWFLAKE.ACCOUNT_USAGE.QUERY_HISTORY
        WHERE START_TIME >= '{start_date.strftime('%Y-%m-%d')}'
          AND START_TIME < '{end_date.strftime('%Y-%m-%d')}'
          AND WAREHOUSE_NAME IS NOT NULL
          {warehouse_filter}
        GROUP BY DATE_TRUNC('DAY', START_TIME), WAREHOUSE_NAME
        ORDER BY DAY, WAREHOUSE_NAME
        """

        cursor.execute(daily_query)
        daily_stats = cursor.fetchall()

        cursor.close()

        # Process results
        warehouses = []
        for row in warehouse_stats:
            wh_name, query_count, cloud_credits, compute_credits, total_seconds, avg_seconds, max_seconds, bytes_scanned, rows_produced = row
            total_credits = (cloud_credits or 0) + (compute_credits or 0)
            warehouses.append({
                'name': wh_name,
                'query_count': query_count,
                'cloud_services_credits': cloud_credits or 0,
                'compute_credits': compute_credits or 0,
                'total_credits': total_credits,
                'total_elapsed_seconds': total_seconds or 0,
                'avg_elapsed_seconds': avg_seconds or 0,
                'max_elapsed_seconds': max_seconds or 0,
                'total_bytes_scanned': bytes_scanned or 0,
                'total_rows_produced': rows_produced or 0,
                'estimated_cost_usd': total_credits * DEFAULT_CREDIT_COST_USD
            })

        # Process top queries
        queries = []
        for row in top_queries:
            query_id, query_text, wh_name, user_name, start_time, elapsed_seconds, cloud_credits, compute_credits, bytes_scanned, rows_produced = row
            total_credits = (cloud_credits or 0) + (compute_credits or 0)
            # Truncate long queries
            query_preview = query_text[:200] if query_text else "N/A"
            if query_text and len(query_text) > 200:
                query_preview += "..."

            queries.append({
                'query_id': query_id,
                'query_text': query_preview,
                'warehouse': wh_name,
                'user': user_name,
                'start_time': start_time.isoformat() if start_time else None,
                'elapsed_seconds': elapsed_seconds or 0,
                'cloud_credits': cloud_credits or 0,
                'compute_credits': compute_credits or 0,
                'total_credits': total_credits,
                'estimated_cost_usd': total_credits * DEFAULT_CREDIT_COST_USD,
                'bytes_scanned': bytes_scanned or 0,
                'rows_produced': rows_produced or 0
            })

        # Process daily stats
        daily_usage = defaultdict(lambda: defaultdict(float))
        for row in daily_stats:
            day, wh_name, compute_credits, query_count = row
            daily_usage[day.strftime('%Y-%m-%d')][wh_name] = {
                'compute_credits': compute_credits or 0,
                'query_count': query_count
            }

        return {
            'start_date': start_date.strftime('%Y-%m-%d'),
            'end_date': end_date.strftime('%Y-%m-%d'),
            'days': days,
            'warehouses': warehouses,
            'top_queries': queries,
            'daily_usage': dict(daily_usage),
            'total_credits': sum(wh['total_credits'] for wh in warehouses),
            'total_cost_usd': sum(wh['estimated_cost_usd'] for wh in warehouses),
            'total_queries': sum(wh['query_count'] for wh in warehouses)
        }

    except Exception as e:
        print(f"{Colors.RED}Error getting warehouse usage: {str(e)}{Colors.RESET}", file=sys.stderr)
        sys.exit(1)


def format_bytes(bytes_value: int) -> str:
    """Format bytes into human-readable string"""
    if bytes_value == 0:
        return "0 B"
    for unit in ['B', 'KB', 'MB', 'GB', 'TB', 'PB']:
        if bytes_value < 1024.0:
            return f"{bytes_value:.2f} {unit}"
        bytes_value /= 1024.0
    return f"{bytes_value:.2f} EB"


def format_duration(seconds: float) -> str:
    """Format seconds into human-readable duration"""
    if seconds < 60:
        return f"{seconds:.1f}s"
    elif seconds < 3600:
        return f"{seconds/60:.1f}m"
    else:
        return f"{seconds/3600:.1f}h"


def print_text_report(result: dict):
    """Print a formatted text report of warehouse usage"""

    print(f"\n{Colors.CYAN}{Colors.BOLD}Snowflake Warehouse Usage Report{Colors.RESET}")
    print(f"Period: {result['start_date']} to {result['end_date']} ({result['days']} days)")
    print("=" * 100)

    # Overall summary
    print(f"\n{Colors.BOLD}Overall Summary:{Colors.RESET}")
    print(f"  Total Credits:     {result['total_credits']:.4f}")
    print(f"  Total Cost:        {Colors.YELLOW}${result['total_cost_usd']:.2f} USD{Colors.RESET}")
    print(f"  Total Queries:     {result['total_queries']:,}")
    print(f"  Credit Price:      ${DEFAULT_CREDIT_COST_USD:.2f}/credit")

    # Warehouse breakdown
    if result['warehouses']:
        print(f"\n{Colors.BOLD}Warehouse Breakdown:{Colors.RESET}")
        print(f"  {'Warehouse':<20} {'Queries':<10} {'Credits':<12} {'Cost':<12} {'Avg Time':<10}")
        print(f"  {'-'*20} {'-'*10} {'-'*12} {'-'*12} {'-'*10}")
        for wh in result['warehouses']:
            print(f"  {wh['name']:<20} {wh['query_count']:<10,} {wh['total_credits']:<12.4f} ${wh['estimated_cost_usd']:<11.2f} {format_duration(wh['avg_elapsed_seconds']):<10}")

    # Top queries
    if result['top_queries']:
        print(f"\n{Colors.BOLD}Top {len(result['top_queries'])} Queries by Credit Usage:{Colors.RESET}")
        for i, query in enumerate(result['top_queries'], 1):
            print(f"\n  {Colors.CYAN}#{i}{Colors.RESET} {Colors.BOLD}{query['warehouse']}{Colors.RESET} by {query['user']}")
            print(f"      Credits:  {query['total_credits']:.6f} (${query['estimated_cost_usd']:.4f})")
            print(f"      Duration: {format_duration(query['elapsed_seconds'])}")
            print(f"      Data:     {format_bytes(query['bytes_scanned'])} scanned, {query['rows_produced']:,} rows")
            print(f"      Query:    {query['query_text'][:150]}")

    # Daily trends
    if result['daily_usage']:
        print(f"\n{Colors.BOLD}Daily Credit Usage:{Colors.RESET}")
        for day in sorted(result['daily_usage'].keys()):
            day_total = sum(wh['compute_credits'] for wh in result['daily_usage'][day].values())
            day_queries = sum(wh['query_count'] for wh in result['daily_usage'][day].values())
            print(f"  {day}: {day_total:.4f} credits, {day_queries:,} queries")

    print("\n" + "=" * 100)
    print(f"{Colors.YELLOW}Note: Costs are estimates based on ${DEFAULT_CREDIT_COST_USD}/credit. Actual costs may vary.{Colors.RESET}\n")


def print_json_report(result: dict):
    """Print a JSON report of warehouse usage"""
    output = {
        "period": {
            "start_date": result['start_date'],
            "end_date": result['end_date'],
            "days": result['days']
        },
        "summary": {
            "total_credits": round(result['total_credits'], 4),
            "total_cost_usd": round(result['total_cost_usd'], 2),
            "total_queries": result['total_queries'],
            "credit_price_usd": DEFAULT_CREDIT_COST_USD
        },
        "warehouses": [
            {
                "name": wh['name'],
                "query_count": wh['query_count'],
                "compute_credits": round(wh['compute_credits'], 4),
                "cloud_services_credits": round(wh['cloud_services_credits'], 4),
                "total_credits": round(wh['total_credits'], 4),
                "estimated_cost_usd": round(wh['estimated_cost_usd'], 2),
                "avg_elapsed_seconds": round(wh['avg_elapsed_seconds'], 2),
                "total_bytes_scanned": wh['total_bytes_scanned']
            }
            for wh in result['warehouses']
        ],
        "top_queries": [
            {
                "rank": i + 1,
                "query_id": q['query_id'],
                "warehouse": q['warehouse'],
                "user": q['user'],
                "start_time": q['start_time'],
                "total_credits": round(q['total_credits'], 6),
                "estimated_cost_usd": round(q['estimated_cost_usd'], 4),
                "elapsed_seconds": round(q['elapsed_seconds'], 2),
                "bytes_scanned": q['bytes_scanned'],
                "rows_produced": q['rows_produced'],
                "query_preview": q['query_text']
            }
            for i, q in enumerate(result['top_queries'])
        ],
        "daily_usage": result['daily_usage']
    }
    print(json.dumps(output, indent=2))


def main():
    parser = argparse.ArgumentParser(
        description="Monitor Snowflake warehouse usage and costs",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__
    )
    parser.add_argument("--warehouse", help="Monitor specific warehouse (default: all)")
    parser.add_argument("--days", type=int, default=7, help="Number of days to analyze (default: 7, max: 30)")
    parser.add_argument("--top", type=int, default=10, help="Show top N queries by credits (default: 10)")
    parser.add_argument("--format", choices=["text", "json"], default="text",
                       help="Output format (default: text)")

    args = parser.parse_args()

    # Validate days
    if args.days < 1 or args.days > 30:
        print(f"{Colors.RED}Error: days must be between 1 and 30{Colors.RESET}", file=sys.stderr)
        sys.exit(1)

    # Initialize Snowflake connection
    conn = get_snowflake_connection()

    # Get warehouse usage
    result = get_warehouse_usage(conn, args.warehouse, args.days, args.top)

    # Print report
    if args.format == "json":
        print_json_report(result)
    else:
        print_text_report(result)

    # Close connection
    conn.close()


if __name__ == "__main__":
    main()
