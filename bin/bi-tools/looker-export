#!/usr/bin/env python3
"""
looker-export - Export BigQuery tables to Looker LookML views

Usage:
  looker-export <table_id> [options]
  looker-export --dataset=<dataset> [options]

Arguments:
  table_id    Table ID to export (format: project.dataset.table)

Options:
  --dataset=<dataset>      Export all tables in a dataset (format: project.dataset)
  --output-dir=<path>      Output directory for LookML files (default: ./lookml)
  --sql-table-name         Use sql_table_name instead of derived table
  --include-measures       Include auto-generated measures (default: false)
  --help, -h               Show this help message

Examples:
  looker-export project.dataset.fct_orders --output-dir=./views
  looker-export --dataset=project.analytics --include-measures
  looker-export project.dataset.dim_customers --sql-table-name
"""

import sys
import os
import argparse
from typing import Dict, List, Optional
from google.cloud import bigquery
from pathlib import Path


class Colors:
    """ANSI color codes for terminal output"""
    RED = '\033[0;31m'
    GREEN = '\033[0;32m'
    YELLOW = '\033[1;33m'
    BLUE = '\033[0;34m'
    CYAN = '\033[0;36m'
    RESET = '\033[0m'
    BOLD = '\033[1m'


def bq_type_to_looker_type(bq_type: str) -> str:
    """
    Map BigQuery data types to Looker dimension types.

    Args:
        bq_type: BigQuery field type

    Returns:
        Looker dimension type
    """
    type_mapping = {
        'STRING': 'string',
        'BYTES': 'string',
        'INTEGER': 'number',
        'INT64': 'number',
        'FLOAT': 'number',
        'FLOAT64': 'number',
        'NUMERIC': 'number',
        'BIGNUMERIC': 'number',
        'BOOLEAN': 'yesno',
        'BOOL': 'yesno',
        'TIMESTAMP': 'time',
        'DATE': 'date',
        'TIME': 'string',
        'DATETIME': 'datetime',
        'GEOGRAPHY': 'string',
        'RECORD': 'string',
        'STRUCT': 'string',
    }

    return type_mapping.get(bq_type.upper(), 'string')


def generate_dimension(field: bigquery.SchemaField, include_sql: bool = True) -> str:
    """
    Generate a Looker dimension definition from a BigQuery field.

    Args:
        field: BigQuery schema field
        include_sql: Whether to include the sql parameter

    Returns:
        LookML dimension definition
    """
    looker_type = bq_type_to_looker_type(field.field_type)

    lines = [f"  dimension: {field.name} {{"]

    # Add description if available
    if field.description:
        lines.append(f'    description: "{field.description}"')

    # Add type
    lines.append(f"    type: {looker_type}")

    # Add SQL reference
    if include_sql:
        lines.append(f"    sql: ${{TABLE}}.{field.name} ;;")

    # Add special handling for time dimensions
    if looker_type in ['time', 'date', 'datetime']:
        lines.append("    datatype: timestamp")
        lines.append("    timeframes: [raw, time, date, week, month, quarter, year]")

    lines.append("  }")

    return '\n'.join(lines)


def generate_measure(field: bigquery.SchemaField) -> Optional[str]:
    """
    Generate a Looker measure definition for numeric fields.

    Args:
        field: BigQuery schema field

    Returns:
        LookML measure definition or None
    """
    if field.field_type not in ['INTEGER', 'INT64', 'FLOAT', 'FLOAT64', 'NUMERIC', 'BIGNUMERIC']:
        return None

    field_name = field.name

    # Common aggregate field patterns
    if field_name.endswith('_count') or field_name == 'count':
        measure_type = 'sum'
    elif field_name.endswith('_total') or field_name.endswith('_amount'):
        measure_type = 'sum'
    else:
        measure_type = 'sum'

    lines = [f"  measure: total_{field_name} {{"]
    lines.append(f"    type: {measure_type}")
    lines.append(f"    sql: ${{TABLE}}.{field_name} ;;")
    lines.append("  }")

    return '\n'.join(lines)


def generate_lookml_view(table: bigquery.Table, use_sql_table_name: bool = False,
                        include_measures: bool = False) -> str:
    """
    Generate a complete LookML view from a BigQuery table.

    Args:
        table: BigQuery table object
        use_sql_table_name: Use sql_table_name instead of derived table
        include_measures: Include auto-generated measures

    Returns:
        Complete LookML view definition
    """
    # Extract table name components
    table_ref = table.reference
    view_name = table_ref.table_id

    lines = [f"view: {view_name} {{"]

    # Add table reference
    if use_sql_table_name:
        full_table_name = f"{table_ref.project}.{table_ref.dataset_id}.{table_ref.table_id}"
        lines.append(f'  sql_table_name: `{full_table_name}` ;;')
    else:
        lines.append("  derived_table: {")
        lines.append("    sql:")
        full_table_name = f"{table_ref.project}.{table_ref.dataset_id}.{table_ref.table_id}"
        lines.append(f"      SELECT * FROM `{full_table_name}`")
        lines.append("      ;;")
        lines.append("  }")

    lines.append("")

    # Add table description if available
    if table.description:
        lines.append(f'  description: "{table.description}"')
        lines.append("")

    # Add primary key if available (look for id field)
    id_fields = [f for f in table.schema if f.name.lower() in ['id', f'{view_name}_id']]
    if id_fields:
        lines.append(f"  dimension: {id_fields[0].name} {{")
        lines.append("    primary_key: yes")
        lines.append("    type: number")
        lines.append(f"    sql: ${{TABLE}}.{id_fields[0].name} ;;")
        lines.append("  }")
        lines.append("")

    # Add dimensions for all fields
    for field in table.schema:
        # Skip if already added as primary key
        if id_fields and field.name == id_fields[0].name:
            continue

        dimension = generate_dimension(field, include_sql=True)
        lines.append(dimension)
        lines.append("")

    # Add count measure (always useful)
    lines.append("  measure: count {")
    lines.append("    type: count")
    lines.append("    drill_fields: [*]")
    lines.append("  }")
    lines.append("")

    # Add measures for numeric fields if requested
    if include_measures:
        for field in table.schema:
            measure = generate_measure(field)
            if measure:
                lines.append(measure)
                lines.append("")

    lines.append("}")

    return '\n'.join(lines)


def export_table_to_lookml(client: bigquery.Client, table_id: str, output_dir: Path,
                           use_sql_table_name: bool = False, include_measures: bool = False) -> bool:
    """
    Export a single BigQuery table to a LookML view file.

    Args:
        client: BigQuery client
        table_id: Full table ID (project.dataset.table)
        output_dir: Output directory for LookML file
        use_sql_table_name: Use sql_table_name instead of derived table
        include_measures: Include auto-generated measures

    Returns:
        True if successful, False otherwise
    """
    try:
        table = client.get_table(table_id)

        # Generate LookML
        lookml = generate_lookml_view(table, use_sql_table_name, include_measures)

        # Create output directory if it doesn't exist
        output_dir.mkdir(parents=True, exist_ok=True)

        # Write to file
        view_name = table.reference.table_id
        output_file = output_dir / f"{view_name}.view.lkml"

        with open(output_file, 'w') as f:
            f.write(lookml)

        print(f"{Colors.GREEN}✓{Colors.RESET} Exported {Colors.CYAN}{view_name}{Colors.RESET} to {output_file}")
        return True

    except Exception as e:
        print(f"{Colors.RED}✗ Error exporting {table_id}: {str(e)}{Colors.RESET}", file=sys.stderr)
        return False


def export_dataset_to_lookml(client: bigquery.Client, dataset_id: str, output_dir: Path,
                             use_sql_table_name: bool = False, include_measures: bool = False):
    """
    Export all tables in a BigQuery dataset to LookML view files.

    Args:
        client: BigQuery client
        dataset_id: Full dataset ID (project.dataset)
        output_dir: Output directory for LookML files
        use_sql_table_name: Use sql_table_name instead of derived table
        include_measures: Include auto-generated measures
    """
    try:
        # List all tables in the dataset
        tables = list(client.list_tables(dataset_id))

        if not tables:
            print(f"{Colors.YELLOW}⚠ No tables found in dataset {dataset_id}{Colors.RESET}")
            return

        print(f"\n{Colors.CYAN}{Colors.BOLD}Exporting {len(tables)} tables from {dataset_id}{Colors.RESET}")
        print("=" * 80)

        success_count = 0
        for table_ref in tables:
            table_id = f"{table_ref.project}.{table_ref.dataset_id}.{table_ref.table_id}"
            if export_table_to_lookml(client, table_id, output_dir, use_sql_table_name, include_measures):
                success_count += 1

        print("=" * 80)
        print(f"\n{Colors.GREEN}{Colors.BOLD}Summary{Colors.RESET}")
        print(f"  Exported: {success_count}/{len(tables)} tables")
        print(f"  Output directory: {output_dir.absolute()}")

        if success_count < len(tables):
            sys.exit(1)

    except Exception as e:
        print(f"{Colors.RED}Error listing tables in dataset {dataset_id}: {str(e)}{Colors.RESET}", file=sys.stderr)
        sys.exit(1)


def main():
    parser = argparse.ArgumentParser(
        description="Export BigQuery tables to Looker LookML views",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__
    )
    parser.add_argument("table_id", nargs='?', help="Table ID to export (project.dataset.table)")
    parser.add_argument("--dataset", help="Export all tables in a dataset (project.dataset)")
    parser.add_argument("--output-dir", default="./lookml", help="Output directory (default: ./lookml)")
    parser.add_argument("--sql-table-name", action="store_true",
                       help="Use sql_table_name instead of derived table")
    parser.add_argument("--include-measures", action="store_true",
                       help="Include auto-generated measures")

    args = parser.parse_args()

    # Validate arguments
    if not args.table_id and not args.dataset:
        parser.error("Either table_id or --dataset must be provided")

    if args.table_id and args.dataset:
        parser.error("Cannot specify both table_id and --dataset")

    # Initialize BigQuery client
    client = bigquery.Client()
    output_dir = Path(args.output_dir)

    # Export based on mode
    if args.dataset:
        export_dataset_to_lookml(client, args.dataset, output_dir,
                                args.sql_table_name, args.include_measures)
    else:
        success = export_table_to_lookml(client, args.table_id, output_dir,
                                        args.sql_table_name, args.include_measures)
        sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
